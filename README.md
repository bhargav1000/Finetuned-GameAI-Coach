# Custom Adaptive Game AI

This project is an **AI assistant designed for the [Vibe Coded AI game](https://github.com/bhargav1000/Vibe-Coded-Game-with-Cursor-PhaserJS)** built with Phaser 3. The AI model was fine-tuned to provide intelligent tactical suggestions during gameplay, featuring Q-learning agents for training data generation and performance improvement.

## ğŸ® Demo Video

![Demo](https://raw.githubusercontent.com/bhargav1000/Custom-Adaptive-GameAI/main/assets/Demo1.gif)

*Watch the AI-enhanced fighting game in action with player-controlled hero vs AI-controlled Purple Knight, featuring real-time tactical suggestions from the fine-tuned Phi-3.5 model!*

## Features

- **Q-Learning Training**: Used for two purposes - generating training data and improving Purple Knight performance
- **Player-Controlled Hero**: Hero knight can be controlled using keyboard or Xbox controller (future controller support)
- **AI-Powered Purple Knight**: Continuously improving combat AI using Q-learning algorithms
- **Advanced Combat System**: Multiple attack types, blocking, stamina management, and armor
- **113 Directional Animations**: Complete 8-directional animation set for immersive combat
- **Physics-based Combat**: Matter.js integration with collision detection and anti-push systems
- **Data Collection**: ChromaDB integration with screenshot capture and event logging
- **Fine-tuned AI Assistant**: Pre-trained model providing real-time tactical suggestions
- **Debug Tools**: Real-time Q-value visualization and combat statistics

## Game Components

### AI System
- **Q-Learning Training**: Used for generating training data and improving Purple Knight performance
- **Player Control**: Hero knight controlled by player using keyboard or Xbox controller
- **Purple Knight AI**: Continuously improving combat AI using Q-learning algorithms
- **Distance-Closing Behavior**: AI prioritizes aggressive engagement over defensive play
- **Dynamic Action Selection**: Context-aware decision making based on distance, health, and opponent state
- **Configurable Parameters**: JSON-based learning rate, epsilon decay, and reward tuning

### Combat Mechanics
- **Multi-layered Attack System**: Melee, special attacks, kicks with wind-up and hit detection
- **Directional Blocking**: 120-degree frontal arc blocking with stamina costs
- **Armor & Durability**: Helmet, breastplate, greaves with damage-over-time degradation
- **Health & Stamina**: Resource management affecting combat capabilities

### Technical Features
- **Anti-Push Physics**: Robust collision system preventing character displacement
- **Predictive Movement**: Future position calculation to prevent physics exploits
- **Animation Consistency**: Global timing control without frame-rate overrides
- **Data Persistence**: Q-table saving/loading for continuous learning

### Game Arena

![Game Arena](https://raw.githubusercontent.com/bhargav1000/Custom-Adaptive-GameAI/main/assets/game_arena.png)

*The medieval boss arena where epic battles between the hero knight and AI-controlled Purple Knight take place. Features dynamic lighting, atmospheric environment, and optimized collision detection.*

### Assets & Credits

**Character Assets**: All character sprites and animations are from [SmallScaleInt](https://smallscaleint.itch.io/) - a solo developer specializing in pixel art assets for top-down games. The 8-directional character animations and combat sprites provide the foundation for the immersive fighting experience.

**Map Assets**: The medieval boss arena environment was generated by ChatGPT, creating a unique atmospheric backdrop for the epic battles between hero and AI-controlled knights.

## Prerequisites

- **Modern web browser** (Chrome, Firefox, Safari, Edge)
- **Python 3.8+** (for backend and AI features)
- **Node.js** (optional, for npm-based development)

## Pre-trained Resources

### Fine-tuned Model Weights

Download the pre-trained model from HuggingFace:
```bash
# Create model directory
mkdir -p model/fine_tuned

# Download from HuggingFace
git lfs install
git clone https://huggingface.co/bhargav1000/Finetuned-Phi3.5-Custom-Game model/fine_tuned/
```

**Model Location**: `model/fine_tuned/`  
**Source**: [HuggingFace Model Repository](https://huggingface.co/bhargav1000/Finetuned-Phi3.5-Custom-Game)

### Training Dataset

Download the training dataset from HuggingFace:
```bash
# Create training data directory
mkdir -p training_data

# Download from HuggingFace
git clone https://huggingface.co/datasets/bhargav1000/Custom-Game-Finetune-Training-Data training_data/
```

**Dataset Location**: `training_data/`  
**Source**: [HuggingFace Dataset Repository](https://huggingface.co/datasets/bhargav1000/Custom-Game-Finetune-Training-Data)

## Installation

### Complete Setup (Recommended)

Install all dependencies for the full experience:
```bash
pip install -r requirements.txt
```

This includes:
- ğŸ® **Game backend** (FastAPI, ChromaDB)
- ğŸ¤– **AI training** (transformers, PEFT, LoRA) 
- ğŸ“Š **Data processing** (numpy, scipy, scikit-learn)
- ğŸ“ˆ **Progress visualization** (tqdm)
- ğŸ”§ **Utilities** (packaging, websockets)

### Enhanced Performance (Optional)

For 2x faster fine-tuning and 50% less memory usage:
```bash
pip install "unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git"
```

### Compatibility Check

If you encounter issues with Phi-3.5 fine-tuning:
```bash
python fix_phi_compatibility.py
```

### Platform Notes

**Apple Silicon Macs (M1/M2/M3):**
- âœ… MPS acceleration automatically detected
- âœ… All dependencies Mac compatible
- âœ… No CUDA requirements

**NVIDIA GPUs:**
- âœ… CUDA acceleration automatic
- âœ… 4-bit quantization supported
- ğŸ”§ Optional: flash-attn for extra performance

**CPU Only:**
- âœ… All features work on CPU
- âš ï¸ Training will be slower
- ğŸ’¡ Consider cloud GPU for fine-tuning

## Quick Start

### ğŸ¯ AI Demo Mode (Recommended)

Experience the complete AI-enhanced fighting game with real-time tactical suggestions:

```bash
# 1. Install dependencies
npm install

# 2. Start AI model server (Terminal 1)
python ai_model_server.py

# 3. Start demo frontend (Terminal 2)  
npm run demo
```

Navigate to `http://localhost:5173/demo.html`

**âœ¨ Demo Features:**
- ğŸ¤– **Fine-tuned Phi-3.5 AI coaching** with tactical suggestions
- ğŸ® **Player vs AI combat** - you control the hero, AI controls the Purple Knight
- ğŸ“Š **Live game analysis** inside the game window
- ğŸ”„ **Auto-suggestions** - toggle AI coaching on/off with a single button
- ğŸ¯ **Integrated AI panel** replaces Q-Learning debug panel
- ğŸ§  **Smart fallback** to rule-based suggestions if model offline
- ğŸ® **Controller Support** - keyboard and Xbox controller input

### AI Interface

![AI Interface](https://raw.githubusercontent.com/bhargav1000/Custom-Adaptive-GameAI/main/assets/ai_interface.png)

*The integrated AI coaching interface showing real-time tactical suggestions, game state analysis, and control scheme display. Features live health/stamina tracking, distance analysis, and contextual combat advice.*

**Optional: Add Data Collection**
```bash
# Terminal 3 (optional): python game_event_microservice/ai_bridge_fastapi.py
```

### ğŸ® Original Game Mode

For the standard game experience without AI assistance:

**Option A: Using npm (Recommended)**
```bash
npm install
npm run dev
```
Navigate to `http://localhost:5173`

**Option B: Using npx**
```bash
npx http-server
```
Navigate to `http://localhost:8080`

**Option C: Using Python**
```bash
python3 -m http.server
```
Navigate to `http://localhost:8000`

### 2. Backend Setup

#### **AI Model Server** (Required for Demo - Port 8766)
```bash
python ai_model_server.py
```
Provides:
- ğŸ¤– **Fine-tuned Phi-3.5 model serving** for tactical suggestions
- ğŸ”„ **Automatic fallback** to rule-based system
- ğŸ–¥ï¸ **Device auto-detection** (CUDA/MPS/CPU)

#### **Data Collection Bridge** (Optional - Port 8765)
```bash
python game_event_microservice/ai_bridge_fastapi.py
```
Provides:
- ğŸ“¸ **Screenshot capture and storage** for training data
- ğŸ“Š **Game event logging** to ChromaDB
- ğŸ” **Semantic search capabilities** for game analysis

### 3. Training Data Generation (Optional - for AI assistant development)

Generate comprehensive training datasets from collected gameplay data:
```bash
python generate_training_data.py
```

This creates:
- **11,741+ training examples** in instruction-following format
- **Tactical analysis** for each game state
- **Strategic recommendations** based on historical win/loss patterns
- **Model-ready datasets** for fine-tuning AI assistants

### 4. Fine-tune AI Model (Optional - for AI assistant)

Fine-tune a Phi-3.5 model using your collected training data:
```bash
# Run fine-tuning
python finetune_phi_model.py


```

This will:
- ğŸ“¥ Download Phi-3.5-mini-instruct model
- ğŸ”§ Apply LoRA fine-tuning with your 11,741+ examples
- ğŸ’¾ Save fine-tuned model for tactical advice generation
- ğŸ§ª Test model with sample game scenarios

**Hardware Requirements:**
- **Recommended**: 8GB+ VRAM (NVIDIA/AMD) or Apple Silicon Mac
- **Minimum**: 16GB+ RAM for CPU-only training





## Game Interface

### ğŸ¯ AI Demo Mode Interface

**Left Side - Game Arena:**
- Player vs AI combat with real-time AI coaching
- You control the hero knight, AI controls the Purple Knight
- Debug controls: **X** (collision boundaries), **F2** (physics), **P** (screenshot)

**Right Side - AI Assistant Panel (Inside Game Window):**
- ğŸ¤– **AI Fighting Coach** - Fine-tuned Phi-3.5 tactical suggestions
- ğŸ’¡ **Current Suggestion** - Latest tactical advice in highlighted box
- ğŸ“Š **Game Analysis** - Live health, stamina, distance, phase tracking
- ğŸ“ **Suggestion History** - Scrollable history of recent AI suggestions
- ğŸ® **Demo Controls** - "AI Suggestions: ON/OFF" toggle button
- ğŸ§  **Model Status** - Shows if using fine-tuned model or fallback

**Bottom Panel - Live Events:**
- Combat event stream with JSON formatting
- Real-time action logging and state changes

### ğŸ® Game Interface

**Player vs AI Combat:**
The game features **player-controlled hero knight** vs **AI-controlled Purple Knight**. You control the hero using keyboard or Xbox controller, while the Purple Knight uses Q-learning AI that continuously improves its combat strategies.

**Debug Controls:**
- **X**: Toggle collision boundary visualization
- **F2**: Toggle physics body debug display
- **P**: Manual screenshot capture

**Interface Panels:**
- **AI Assistant Panel** (right side): Tactical suggestions from AI coach
- **Events Panel** (bottom): Live combat event log
- **Health/Stamina Bars**: Visual representation of knight status

## AI Configuration

### Learning Parameters
Modify `pknight.json` to adjust Purple Knight AI behavior:
- **learningRate**: How quickly AI adapts (0.05-0.1)
- **discountFactor**: Future reward importance (0.9)
- **epsilonStart/Min**: Exploration vs exploitation balance
- **decaySteps**: Learning progression rate

### Combat Behavior
The AI system includes:
- **Distance-based decision making**: Different strategies for close/medium/far combat
- **Aggressive bias**: Heavy penalties for passive behavior
- **Contextual rewards**: Bonuses for situationally appropriate actions
- **Continuous learning**: Q-tables persist between sessions
- **Training data generation**: Q-learning used to generate diverse combat scenarios

## Project Structure

```
Custom-Adaptive-GameAI/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.js              # Core game logic and AI
â”‚   â””â”€â”€ RL.js                # Q-learning implementation
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ character/           # 14 animation spritesheets
â”‚   â””â”€â”€ map/                 # Arena and environment assets
â”œâ”€â”€ game_event_microservice/
â”‚   â””â”€â”€ ai_bridge_fastapi.py # Data collection backend
â”œâ”€â”€ training_data/           # Generated training datasets
â”‚   â”œâ”€â”€ [session_folders]/   # Screenshots, metadata, training data
â”‚   â””â”€â”€ summary/             # Aggregated datasets and statistics
â”œâ”€â”€ generate_training_data.py # Training data generation script
â”œâ”€â”€ finetune_phi_model.py    # Phi-3.5 model fine-tuning
â”œâ”€â”€ demo.html               # ğŸ¯ AI-enhanced demo interface
â”œâ”€â”€ ai_model_server.py      # ğŸ¤– Separate AI model server (Port 8766)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.js             # Original game logic
â”‚   â””â”€â”€ demo.js             # ğŸ¤– AI demo with suggestions
â”œâ”€â”€ heroknight.json          # Hero AI configuration
â”œâ”€â”€ pknight.json            # Purple knight AI configuration
â””â”€â”€ index.html              # Original game interface
```

## Troubleshooting

### Demo System Issues (Fixed in v1.1)

**Network Connectivity (v1.2)**
- âœ… **Fixed**: Unified all endpoints to port 8766 for simplified architecture
- âœ… **Fixed**: Added missing DOM elements for suggestion history display
- âœ… **Fixed**: Resolved UI method initialization errors
- âœ… **Fixed**: Gamepad initialization with proper error handling

**Movement & Combat (v1.2)**
- âœ… **Fixed**: Hero movement with appropriate mass and friction settings
- âœ… **Fixed**: Purple Knight AI behavior - now actively pursues and attacks
- âœ… **Fixed**: Game speed maintained at 4x for accelerated AI training
- âœ… **Fixed**: Added proper movement to all Purple Knight AI actions
- âœ… **Enhanced**: Text cleaning for AI suggestions to show only relevant advice

**Unified Port Architecture**
- **Port 8766**: AI Model Server (`python ai_model_server.py`) - **ALL DEMO ENDPOINTS**
  - AI suggestions, game events, screenshots, model info
  - Single server for complete demo functionality
- **Port 8765**: Data Collection Bridge - **OPTIONAL**
  - Only needed for ChromaDB training data collection

**Debug Controls**
- **Debug Keys**: X (boundaries), F2 (physics), P (screenshot)

## Research Applications

This project demonstrates:
- **Q-learning for training data generation** in competitive environments
- **Player vs AI interaction** with intelligent opponent adaptation
- **Behavioral analysis** through comprehensive data collection
- **Physics-based AI** with realistic movement and collision constraints
- **AI assistant training** using gameplay data for strategic coaching models

## Training Data Features

### Generated Dataset Statistics
- **11,741 training examples** from 134 game sessions
- **99.3% hero win rate** providing winning strategy patterns
- **Multi-phase coverage**: Early game, mid game, critical moments, endgame
- **Tactical depth**: Health management, stamina optimization, positioning advice

### AI Assistant Training Format
Each training example includes:
```json
{
  "instruction": "You are an expert fighting game coach. Analyze this game state and provide tactical advice for the hero player.",
  "input": "Hero: 73% HP, 69% stamina, unsheath-s. Knight: 0% HP, 24% stamina, die. Distance: close, Phase: game_over",
  "output": "You have a significant health advantage! Control the pace"
}
```

### Model Compatibility
The training dataset is optimized for fine-tuning:
- **Phi-3.5 Mini Instruct** (3.8B parameters)
- **Llama 3.1 8B Instruct** (8B parameters)  
- **Mistral 7B Instruct** (7B parameters)
- Other instruction-following language models