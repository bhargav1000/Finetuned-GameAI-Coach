# Custom Adaptive Game AI

This project is an **AI assistant designed for the [Vibe Coded AI game](https://github.com/bhargav1000/Vibe-Coded-Game-with-Cursor-PhaserJS)** built with Phaser 3. The AI model was fine-tuned to provide intelligent tactical suggestions during gameplay, featuring Q-learning agents for training data generation and performance improvement.

## 🎮 Demo Video

![Demo](https://raw.githubusercontent.com/bhargav1000/Custom-Adaptive-GameAI/main/assets/Demo1.gif)

*Watch the AI-enhanced fighting game in action with player-controlled hero vs AI-controlled Purple Knight, featuring real-time tactical suggestions from the fine-tuned Phi-3.5 model!*

## Features

- **Q-Learning Training**: Used for two purposes - generating training data and improving Purple Knight performance
- **Player-Controlled Hero**: Hero knight can be controlled using keyboard or Xbox controller (future controller support)
- **AI-Powered Purple Knight**: Continuously improving combat AI using Q-learning algorithms
- **Advanced Combat System**: Multiple attack types, blocking, stamina management, and armor
- **113 Directional Animations**: Complete 8-directional animation set for immersive combat
- **Physics-based Combat**: Matter.js integration with collision detection and anti-push systems
- **Data Collection**: ChromaDB integration with screenshot capture and event logging
- **Fine-tuned AI Assistant**: Pre-trained model providing real-time tactical suggestions
- **Debug Tools**: Real-time Q-value visualization and combat statistics

## Game Components

### AI System
- **Q-Learning Training**: Used for generating training data and improving Purple Knight performance
- **Player Control**: Hero knight controlled by player using keyboard or Xbox controller
- **Purple Knight AI**: Continuously improving combat AI using Q-learning algorithms
- **Distance-Closing Behavior**: AI prioritizes aggressive engagement over defensive play
- **Dynamic Action Selection**: Context-aware decision making based on distance, health, and opponent state
- **Configurable Parameters**: JSON-based learning rate, epsilon decay, and reward tuning

### Combat Mechanics
- **Multi-layered Attack System**: Melee, special attacks, kicks with wind-up and hit detection
- **Directional Blocking**: 120-degree frontal arc blocking with stamina costs
- **Armor & Durability**: Helmet, breastplate, greaves with damage-over-time degradation
- **Health & Stamina**: Resource management affecting combat capabilities

### Technical Features
- **Anti-Push Physics**: Robust collision system preventing character displacement
- **Predictive Movement**: Future position calculation to prevent physics exploits
- **Animation Consistency**: Global timing control without frame-rate overrides
- **Data Persistence**: Q-table saving/loading for continuous learning

### Game Arena

![Game Arena](https://raw.githubusercontent.com/bhargav1000/Custom-Adaptive-GameAI/main/assets/game_arena.png)

*The medieval boss arena where epic battles between the hero knight and AI-controlled Purple Knight take place. Features dynamic lighting, atmospheric environment, and optimized collision detection.*

### Assets & Credits

**Character Assets**: All character sprites and animations are from [SmallScaleInt](https://smallscaleint.itch.io/) - a solo developer specializing in pixel art assets for top-down games. The 8-directional character animations and combat sprites provide the foundation for the immersive fighting experience.

**Map Assets**: The medieval boss arena environment was generated by ChatGPT, creating a unique atmospheric backdrop for the epic battles between hero and AI-controlled knights.

## Prerequisites

- **Modern web browser** (Chrome, Firefox, Safari, Edge)
- **Python 3.8+** (for backend and AI features)
- **Node.js** (optional, for npm-based development)

## Pre-trained Resources

### Fine-tuned Model Weights

Download the pre-trained model from HuggingFace:
```bash
# Create model directory
mkdir -p model/fine_tuned

# Download from HuggingFace
git lfs install
git clone https://huggingface.co/bhargav1000/Finetuned-Phi3.5-Custom-Game model/fine_tuned/
```

**Model Location**: `model/fine_tuned/`  
**Source**: [HuggingFace Model Repository](https://huggingface.co/bhargav1000/Finetuned-Phi3.5-Custom-Game)

### Training Dataset

Download the training dataset from HuggingFace:
```bash
# Create training data directory
mkdir -p training_data

# Download from HuggingFace
git clone https://huggingface.co/datasets/bhargav1000/Custom-Game-Finetune-Training-Data training_data/
```

**Dataset Location**: `training_data/`  
**Source**: [HuggingFace Dataset Repository](https://huggingface.co/datasets/bhargav1000/Custom-Game-Finetune-Training-Data)

## Installation

### Complete Setup (Recommended)

Install all dependencies for the full experience:
```bash
pip install -r requirements.txt
```

This includes:
- 🎮 **Game backend** (FastAPI, ChromaDB)
- 🤖 **AI training** (transformers, PEFT, LoRA) 
- 📊 **Data processing** (numpy, scipy, scikit-learn)
- 📈 **Progress visualization** (tqdm)
- 🔧 **Utilities** (packaging, websockets)

### Enhanced Performance (Optional)

For 2x faster fine-tuning and 50% less memory usage:
```bash
pip install "unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git"
```

### Compatibility Check

If you encounter issues with Phi-3.5 fine-tuning:
```bash
python fix_phi_compatibility.py
```

### Platform Notes

**Apple Silicon Macs (M1/M2/M3):**
- ✅ MPS acceleration automatically detected
- ✅ All dependencies Mac compatible
- ✅ No CUDA requirements

**NVIDIA GPUs:**
- ✅ CUDA acceleration automatic
- ✅ 4-bit quantization supported
- 🔧 Optional: flash-attn for extra performance

**CPU Only:**
- ✅ All features work on CPU
- ⚠️ Training will be slower
- 💡 Consider cloud GPU for fine-tuning

## Quick Start

### 🎯 AI Demo Mode (Recommended)

Experience the complete AI-enhanced fighting game with real-time tactical suggestions:

```bash
# 1. Install dependencies
npm install

# 2. Start AI model server (Terminal 1)
python ai_model_server.py

# 3. Start demo frontend (Terminal 2)  
npm run demo
```

Navigate to `http://localhost:5173/demo.html`

**✨ Demo Features:**
- 🤖 **Fine-tuned Phi-3.5 AI coaching** with tactical suggestions
- 🎮 **Player vs AI combat** - you control the hero, AI controls the Purple Knight
- 📊 **Live game analysis** inside the game window
- 🔄 **Auto-suggestions** - toggle AI coaching on/off with a single button
- 🎯 **Integrated AI panel** replaces Q-Learning debug panel
- 🧠 **Smart fallback** to rule-based suggestions if model offline
- 🎮 **Controller Support** - keyboard and Xbox controller input

### AI Interface

![AI Interface](https://raw.githubusercontent.com/bhargav1000/Custom-Adaptive-GameAI/main/assets/ai_interface.png)

*The integrated AI coaching interface showing real-time tactical suggestions, game state analysis, and control scheme display. Features live health/stamina tracking, distance analysis, and contextual combat advice.*

**Optional: Add Data Collection**
```bash
# Terminal 3 (optional): python game_event_microservice/ai_bridge_fastapi.py
```

### 🎮 Original Game Mode

For the standard game experience without AI assistance:

**Option A: Using npm (Recommended)**
```bash
npm install
npm run dev
```
Navigate to `http://localhost:5173`

**Option B: Using npx**
```bash
npx http-server
```
Navigate to `http://localhost:8080`

**Option C: Using Python**
```bash
python3 -m http.server
```
Navigate to `http://localhost:8000`

### 2. Backend Setup

#### **AI Model Server** (Required for Demo - Port 8766)
```bash
python ai_model_server.py
```
Provides:
- 🤖 **Fine-tuned Phi-3.5 model serving** for tactical suggestions
- 🔄 **Automatic fallback** to rule-based system
- 🖥️ **Device auto-detection** (CUDA/MPS/CPU)

#### **Data Collection Bridge** (Optional - Port 8765)
```bash
python game_event_microservice/ai_bridge_fastapi.py
```
Provides:
- 📸 **Screenshot capture and storage** for training data
- 📊 **Game event logging** to ChromaDB
- 🔍 **Semantic search capabilities** for game analysis

### 3. Training Data Generation (Optional - for AI assistant development)

Generate comprehensive training datasets from collected gameplay data:
```bash
python generate_training_data.py
```

This creates:
- **11,741+ training examples** in instruction-following format
- **Tactical analysis** for each game state
- **Strategic recommendations** based on historical win/loss patterns
- **Model-ready datasets** for fine-tuning AI assistants

### 4. Fine-tune AI Model (Optional - for AI assistant)

Fine-tune a Phi-3.5 model using your collected training data:
```bash
# Run fine-tuning
python finetune_phi_model.py


```

This will:
- 📥 Download Phi-3.5-mini-instruct model
- 🔧 Apply LoRA fine-tuning with your 11,741+ examples
- 💾 Save fine-tuned model for tactical advice generation
- 🧪 Test model with sample game scenarios

**Hardware Requirements:**
- **Recommended**: 8GB+ VRAM (NVIDIA/AMD) or Apple Silicon Mac
- **Minimum**: 16GB+ RAM for CPU-only training





## Game Interface

### 🎯 AI Demo Mode Interface

**Left Side - Game Arena:**
- Player vs AI combat with real-time AI coaching
- You control the hero knight, AI controls the Purple Knight
- Debug controls: **X** (collision boundaries), **F2** (physics), **P** (screenshot)

**Right Side - AI Assistant Panel (Inside Game Window):**
- 🤖 **AI Fighting Coach** - Fine-tuned Phi-3.5 tactical suggestions
- 💡 **Current Suggestion** - Latest tactical advice in highlighted box
- 📊 **Game Analysis** - Live health, stamina, distance, phase tracking
- 📝 **Suggestion History** - Scrollable history of recent AI suggestions
- 🎮 **Demo Controls** - "AI Suggestions: ON/OFF" toggle button
- 🧠 **Model Status** - Shows if using fine-tuned model or fallback

**Bottom Panel - Live Events:**
- Combat event stream with JSON formatting
- Real-time action logging and state changes

### 🎮 Game Interface

**Player vs AI Combat:**
The game features **player-controlled hero knight** vs **AI-controlled Purple Knight**. You control the hero using keyboard or Xbox controller, while the Purple Knight uses Q-learning AI that continuously improves its combat strategies.

**Debug Controls:**
- **X**: Toggle collision boundary visualization
- **F2**: Toggle physics body debug display
- **P**: Manual screenshot capture

**Interface Panels:**
- **AI Assistant Panel** (right side): Tactical suggestions from AI coach
- **Events Panel** (bottom): Live combat event log
- **Health/Stamina Bars**: Visual representation of knight status

## AI Configuration

### Learning Parameters
Modify `pknight.json` to adjust Purple Knight AI behavior:
- **learningRate**: How quickly AI adapts (0.05-0.1)
- **discountFactor**: Future reward importance (0.9)
- **epsilonStart/Min**: Exploration vs exploitation balance
- **decaySteps**: Learning progression rate

### Combat Behavior
The AI system includes:
- **Distance-based decision making**: Different strategies for close/medium/far combat
- **Aggressive bias**: Heavy penalties for passive behavior
- **Contextual rewards**: Bonuses for situationally appropriate actions
- **Continuous learning**: Q-tables persist between sessions
- **Training data generation**: Q-learning used to generate diverse combat scenarios

## Project Structure

```
Custom-Adaptive-GameAI/
├── src/
│   ├── main.js              # Core game logic and AI
│   └── RL.js                # Q-learning implementation
├── assets/
│   ├── character/           # 14 animation spritesheets
│   └── map/                 # Arena and environment assets
├── game_event_microservice/
│   └── ai_bridge_fastapi.py # Data collection backend
├── training_data/           # Generated training datasets
│   ├── [session_folders]/   # Screenshots, metadata, training data
│   └── summary/             # Aggregated datasets and statistics
├── generate_training_data.py # Training data generation script
├── finetune_phi_model.py    # Phi-3.5 model fine-tuning
├── demo.html               # 🎯 AI-enhanced demo interface
├── ai_model_server.py      # 🤖 Separate AI model server (Port 8766)
├── src/
│   ├── main.js             # Original game logic
│   └── demo.js             # 🤖 AI demo with suggestions
├── heroknight.json          # Hero AI configuration
├── pknight.json            # Purple knight AI configuration
└── index.html              # Original game interface
```

## Troubleshooting

### Demo System Issues (Fixed in v1.1)

**Network Connectivity (v1.2)**
- ✅ **Fixed**: Unified all endpoints to port 8766 for simplified architecture
- ✅ **Fixed**: Added missing DOM elements for suggestion history display
- ✅ **Fixed**: Resolved UI method initialization errors
- ✅ **Fixed**: Gamepad initialization with proper error handling

**Movement & Combat (v1.2)**
- ✅ **Fixed**: Hero movement with appropriate mass and friction settings
- ✅ **Fixed**: Purple Knight AI behavior - now actively pursues and attacks
- ✅ **Fixed**: Game speed maintained at 4x for accelerated AI training
- ✅ **Fixed**: Added proper movement to all Purple Knight AI actions
- ✅ **Enhanced**: Text cleaning for AI suggestions to show only relevant advice

**Unified Port Architecture**
- **Port 8766**: AI Model Server (`python ai_model_server.py`) - **ALL DEMO ENDPOINTS**
  - AI suggestions, game events, screenshots, model info
  - Single server for complete demo functionality
- **Port 8765**: Data Collection Bridge - **OPTIONAL**
  - Only needed for ChromaDB training data collection

**Debug Controls**
- **Debug Keys**: X (boundaries), F2 (physics), P (screenshot)

## Research Applications

This project demonstrates:
- **Q-learning for training data generation** in competitive environments
- **Player vs AI interaction** with intelligent opponent adaptation
- **Behavioral analysis** through comprehensive data collection
- **Physics-based AI** with realistic movement and collision constraints
- **AI assistant training** using gameplay data for strategic coaching models

## Training Data Features

### Generated Dataset Statistics
- **11,741 training examples** from 134 game sessions
- **99.3% hero win rate** providing winning strategy patterns
- **Multi-phase coverage**: Early game, mid game, critical moments, endgame
- **Tactical depth**: Health management, stamina optimization, positioning advice

### AI Assistant Training Format
Each training example includes:
```json
{
  "instruction": "You are an expert fighting game coach. Analyze this game state and provide tactical advice for the hero player.",
  "input": "Hero: 73% HP, 69% stamina, unsheath-s. Knight: 0% HP, 24% stamina, die. Distance: close, Phase: game_over",
  "output": "You have a significant health advantage! Control the pace"
}
```

### Model Compatibility
The training dataset is optimized for fine-tuning:
- **Phi-3.5 Mini Instruct** (3.8B parameters)
- **Llama 3.1 8B Instruct** (8B parameters)  
- **Mistral 7B Instruct** (7B parameters)
- Other instruction-following language models